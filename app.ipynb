{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING THE FEATURES - COMMENTS, FILES_CHANGES, LINES_ADDED, LINES_REMOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_csv.csv')  # replace 'your_data.csv' with your actual data path\n",
    "\n",
    "# data\n",
    "# data.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])  # 0 for 'spam', 1 for 'not_spam'\n",
    "\n",
    "# Select features and target\n",
    "X = data[['comments', 'files_changed', 'lines_added', 'lines_removed']]\n",
    "y = data['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8879310344827587\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.8653846153846154\n",
      "F1 Score: 0.8737864077669902\n",
      "Confusion Matrix:\n",
      " [[58  6]\n",
      " [ 7 45]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "random_forest_accuracy = accuracy_score(y_test, y_pred)\n",
    "random_forest_precision = precision_score(y_test, y_pred)\n",
    "random_forest_recall = recall_score(y_test, y_pred)\n",
    "random_forest_f1 = f1_score(y_test, y_pred)\n",
    "random_forest_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", random_forest_accuracy)\n",
    "print(\"Precision:\", random_forest_precision)\n",
    "print(\"Recall:\", random_forest_recall)\n",
    "print(\"F1 Score:\", random_forest_f1)\n",
    "print(\"Confusion Matrix:\\n\", random_forest_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING LOGISTIC REGRESSION WITHOUT TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.896551724137931\n",
      "Precision: 0.8703703703703703\n",
      "Recall: 0.9038461538461539\n",
      "F1 Score: 0.8867924528301887\n",
      "Confusion Matrix:\n",
      " [[57  7]\n",
      " [ 5 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "logistice_regression_accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "logistice_regression_precision = precision_score(y_test, y_pred_logistic)\n",
    "logistice_regression_recall = recall_score(y_test, y_pred_logistic)\n",
    "logistice_regression_f1 = f1_score(y_test, y_pred_logistic)\n",
    "logistice_regression_conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "# Print results\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", logistice_regression_accuracy)\n",
    "print(\"Precision:\", logistice_regression_precision)\n",
    "print(\"Recall:\", logistice_regression_recall)\n",
    "print(\"F1 Score:\", logistice_regression_f1)\n",
    "print(\"Confusion Matrix:\\n\", logistice_regression_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING THE FEATURES - TITLE, COMMENTS, FILES_CHANGES, LINES_ADDED, LINES_REMOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_csv.csv')  # Replace with your actual file path\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF encoding for the 'title' feature\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Adjust max_features based on your data\n",
    "tfidf_vectorizer\n",
    "title_tfidf = tfidf_vectorizer.fit_transform(data['title']).toarray()\n",
    "# title_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF features with existing numerical features\n",
    "numerical_features = data[['comments', 'files_changed', 'lines_added', 'lines_removed']]\n",
    "X = pd.concat([pd.DataFrame(title_tfidf), numerical_features.reset_index(drop=True)], axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all column names to strings\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Then split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Git PR ML Project\\venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# trying user input\n",
    "X_test_custom = pd.DataFrame([[1, 10, 20, 5]])\n",
    "X_test_custom = pd.concat([pd.DataFrame(tfidf_vectorizer.transform(['Readme update']).toarray()), X_test_custom], axis=1)\n",
    "X_test_custom = scaler.transform(X_test_custom)\n",
    "y_pred_custom = model.predict(X_test_custom)\n",
    "\n",
    "# y_pred_custom.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9655172413793104\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9629629629629629\n",
      "Confusion Matrix:\n",
      " [[60  4]\n",
      " [ 0 52]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "random_forest_with_TITLE_accuracy = accuracy_score(y_test, y_pred)\n",
    "random_forest_with_TITLE_precision = precision_score(y_test, y_pred)\n",
    "random_forest_with_TITLE_recall = recall_score(y_test, y_pred)\n",
    "random_forest_with_TITLE_f1 = f1_score(y_test, y_pred)\n",
    "random_forest_with_TITLE_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", random_forest_with_TITLE_accuracy)\n",
    "print(\"Precision:\", random_forest_with_TITLE_precision)\n",
    "print(\"Recall:\", random_forest_with_TITLE_recall)\n",
    "print(\"F1 Score:\", random_forest_with_TITLE_f1)\n",
    "print(\"Confusion Matrix:\\n\", random_forest_with_TITLE_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING LOGISTIC REGRESSION WITH TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.9482758620689655\n",
      "Precision: 0.9423076923076923\n",
      "Recall: 0.9423076923076923\n",
      "F1 Score: 0.9423076923076923\n",
      "Confusion Matrix:\n",
      " [[61  3]\n",
      " [ 3 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "logistice_regression_with_TITLE_accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "logistice_regression_with_TITLE_precision = precision_score(y_test, y_pred_logistic)\n",
    "logistice_regression_with_TITLE_recall = recall_score(y_test, y_pred_logistic)\n",
    "logistice_regression_with_TITLE_f1 = f1_score(y_test, y_pred_logistic)\n",
    "logistice_regression_with_TITLE_conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "# Print results\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", logistice_regression_with_TITLE_accuracy)\n",
    "print(\"Precision:\", logistice_regression_with_TITLE_precision)\n",
    "print(\"Recall:\", logistice_regression_with_TITLE_recall)\n",
    "print(\"F1 Score:\", logistice_regression_with_TITLE_f1)\n",
    "print(\"Confusion Matrix:\\n\", logistice_regression_with_TITLE_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9655172413793104\n",
      "Precision: 0.9444444444444444\n",
      "Recall: 0.9807692307692307\n",
      "F1 Score: 0.9622641509433962\n",
      "Confusion Matrix:\n",
      " [[61  3]\n",
      " [ 1 51]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv(\"data_csv.csv\")  # Replace 'data.csv' with your data file\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Step 2: Handle categorical and text features\n",
    "# TF-IDF vectorization for 'title' column\n",
    "tfidf = TfidfVectorizer(max_features=100)  # adjust max_features based on vocabulary size\n",
    "\n",
    "# Step 3: Column transformer to handle different types of preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"title_tfidf\", tfidf, \"title\"),  # Apply TF-IDF to the 'title' column\n",
    "        (\"num\", StandardScaler(), [\"comments\", \"files_changed\", \"lines_added\", \"lines_removed\"])\n",
    "    ],\n",
    "    remainder=\"drop\"  # drop columns that are not explicitly mentioned\n",
    ")\n",
    "\n",
    "# Step 4: Create a pipeline with preprocessing and the model\n",
    "pipeline = make_pipeline(preprocessor, RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Step 5: Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=\"spam\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"spam\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"spam\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Precision: 0.93\n",
      "F1 Score: 0.96\n",
      "Recall: 1.00\n",
      "Confusion Matrix:\n",
      " [[90  6]\n",
      " [ 0 78]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_32372\\3013115674.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.82863856 -0.82863856 -0.08665082 -0.82863856 -0.45764469 -0.45764469\n",
      " -1.19963244 -0.45764469  2.13931242 -1.19963244 -0.08665082 -0.82863856\n",
      "  0.28434305 -1.19963244  2.88130016 -0.82863856  0.65533693 -0.45764469\n",
      " -0.82863856 -0.45764469 -0.08665082 -1.19963244  1.39732467  0.28434305\n",
      "  1.0263308  -0.08665082  0.65533693 -0.82863856 -1.19963244  2.13931242\n",
      " -0.82863856 -0.45764469  1.0263308  -0.45764469 -0.82863856  0.28434305\n",
      "  0.65533693 -1.19963244  1.39732467  1.76831854 -0.08665082  1.0263308\n",
      " -0.82863856 -0.45764469 -0.08665082 -1.19963244  0.65533693  0.28434305\n",
      " -0.45764469 -0.08665082  0.65533693 -0.45764469 -0.82863856  1.39732467\n",
      "  0.65533693 -0.45764469  0.28434305 -0.82863856  1.0263308  -0.45764469\n",
      " -1.19963244 -0.82863856  1.39732467 -0.08665082 -0.45764469 -1.19963244\n",
      " -0.82863856  0.65533693 -0.08665082 -0.45764469 -1.19963244  0.28434305\n",
      " -0.08665082 -0.45764469  0.28434305 -0.82863856 -0.08665082  0.28434305\n",
      "  2.13931242 -0.45764469 -0.08665082  0.65533693 -0.82863856 -0.82863856\n",
      "  1.0263308  -0.08665082  1.39732467 -0.82863856  0.28434305  1.76831854\n",
      "  0.65533693 -0.82863856 -0.08665082 -0.45764469 -0.82863856  0.28434305\n",
      "  1.0263308  -1.19963244  1.39732467 -0.08665082 -0.82863856 -1.19963244\n",
      " -0.45764469  0.65533693  0.28434305  1.76831854 -0.08665082 -0.45764469\n",
      "  0.65533693  0.28434305 -0.82863856  1.0263308  -0.45764469 -0.08665082\n",
      "  1.39732467 -0.82863856  0.65533693  1.0263308   0.28434305 -0.45764469\n",
      " -0.82863856 -1.19963244  1.0263308   0.28434305  1.39732467 -0.45764469\n",
      " -0.08665082  0.65533693  2.13931242  1.0263308  -0.08665082  0.28434305\n",
      " -0.82863856 -0.45764469  1.39732467 -0.82863856  0.28434305  1.0263308\n",
      " -0.08665082 -1.19963244 -0.08665082  0.65533693  1.76831854 -0.45764469\n",
      " -0.82863856  1.39732467 -0.45764469  1.0263308  -0.82863856 -0.08665082\n",
      "  0.28434305 -0.45764469  0.65533693 -1.19963244  1.76831854 -0.08665082\n",
      "  0.28434305  1.0263308  -0.45764469 -0.82863856  0.65533693  0.28434305\n",
      " -0.08665082  0.28434305 -0.82863856 -0.45764469 -0.45764469  1.0263308\n",
      "  0.65533693 -0.82863856  0.28434305 -1.19963244  1.0263308   1.39732467\n",
      " -0.08665082 -0.45764469  0.65533693  0.28434305  0.65533693 -0.82863856\n",
      " -0.45764469 -1.19963244 -0.82863856 -0.45764469 -1.19963244 -1.19963244\n",
      " -0.45764469  1.0263308  -0.45764469 -0.45764469  1.76831854  1.0263308\n",
      "  0.28434305 -0.82863856  2.13931242 -0.82863856 -1.19963244 -0.82863856\n",
      "  0.65533693 -1.19963244  2.13931242 -0.45764469 -0.82863856 -0.45764469\n",
      " -0.45764469  1.76831854 -1.19963244 -0.82863856 -0.45764469 -0.08665082\n",
      "  1.76831854 -0.82863856 -1.19963244 -0.82863856 -0.82863856  1.39732467\n",
      "  1.76831854  2.13931242 -0.45764469  0.28434305  1.76831854 -0.45764469\n",
      "  1.39732467 -1.19963244 -0.45764469 -0.82863856  2.13931242 -0.82863856\n",
      " -1.19963244  1.39732467 -1.19963244 -0.45764469 -0.08665082 -0.08665082\n",
      " -0.45764469 -0.45764469  1.76831854  0.65533693 -0.45764469 -1.19963244\n",
      " -0.45764469  0.28434305 -0.82863856 -0.08665082 -1.19963244 -0.45764469\n",
      " -0.45764469 -1.19963244 -0.45764469  2.13931242 -0.82863856  0.65533693\n",
      "  2.13931242 -0.45764469 -0.82863856 -1.19963244  0.28434305 -0.45764469\n",
      " -0.82863856 -1.19963244 -0.45764469 -0.82863856 -0.45764469 -1.19963244\n",
      " -0.82863856 -0.45764469 -1.19963244 -0.82863856 -1.19963244 -0.82863856\n",
      " -0.82863856 -0.45764469  2.13931242 -0.45764469 -0.08665082 -0.82863856\n",
      "  0.65533693 -1.19963244  1.0263308  -1.19963244 -0.08665082 -0.08665082\n",
      " -0.45764469 -0.82863856 -0.82863856  0.65533693 -1.19963244 -0.45764469\n",
      " -0.45764469  0.65533693 -0.45764469 -0.45764469 -0.45764469 -1.19963244\n",
      "  0.65533693 -0.08665082  2.13931242 -0.82863856  1.0263308   0.65533693\n",
      "  1.76831854 -0.45764469 -0.82863856 -0.08665082  2.13931242 -0.45764469\n",
      " -0.08665082 -1.19963244 -0.08665082 -1.19963244 -0.08665082 -0.82863856\n",
      " -0.45764469  2.13931242 -0.82863856 -0.82863856  1.76831854 -1.19963244\n",
      "  0.28434305  0.65533693  1.76831854 -0.45764469 -0.45764469  2.13931242\n",
      " -1.19963244 -1.19963244  1.76831854 -0.08665082 -1.19963244 -0.45764469\n",
      " -0.45764469 -0.82863856 -0.45764469  0.65533693 -0.45764469 -0.82863856\n",
      "  1.39732467 -0.45764469 -0.45764469  1.0263308   1.76831854 -0.45764469\n",
      " -0.45764469 -0.82863856  1.0263308   2.13931242  0.65533693 -0.08665082\n",
      "  0.28434305 -1.19963244 -0.45764469 -1.19963244 -0.82863856  1.0263308\n",
      " -0.45764469  1.76831854 -0.82863856 -1.19963244 -0.82863856 -0.82863856\n",
      " -1.19963244 -0.82863856 -0.82863856  0.28434305  0.28434305  1.39732467\n",
      "  1.39732467 -0.82863856  2.13931242 -0.45764469  1.76831854 -0.45764469\n",
      " -1.19963244  0.28434305 -0.45764469 -0.08665082  1.0263308  -0.08665082\n",
      "  0.28434305 -0.82863856 -0.82863856 -0.45764469 -0.45764469 -1.19963244\n",
      " -0.45764469 -1.19963244  1.76831854 -0.82863856 -1.19963244 -0.45764469\n",
      "  0.28434305 -1.19963244  1.76831854 -0.82863856 -0.08665082 -0.82863856\n",
      "  2.13931242 -0.45764469  0.28434305 -0.08665082  1.39732467  1.0263308\n",
      "  1.0263308  -0.45764469  0.28434305  1.39732467  1.39732467 -1.19963244\n",
      " -0.82863856  1.39732467 -0.82863856 -0.45764469  1.76831854 -0.82863856\n",
      " -0.08665082 -0.45764469 -0.08665082 -0.45764469 -0.45764469 -0.45764469\n",
      " -1.19963244  0.28434305 -0.45764469  2.13931242 -0.82863856 -1.19963244\n",
      "  2.13931242  0.28434305 -1.19963244 -0.45764469  0.65533693 -1.19963244\n",
      " -0.45764469 -0.82863856  1.76831854 -0.45764469 -0.08665082  1.76831854\n",
      " -1.19963244  2.13931242  0.28434305  2.13931242  1.76831854 -1.19963244\n",
      "  0.65533693  1.39732467 -1.19963244  2.13931242  2.13931242 -0.08665082\n",
      " -0.45764469  1.76831854  0.65533693 -0.82863856 -1.19963244  1.39732467\n",
      " -0.82863856 -1.19963244 -0.82863856  0.65533693  1.0263308  -0.82863856\n",
      " -0.08665082  1.0263308   2.13931242 -0.45764469  0.65533693  1.0263308\n",
      " -0.82863856 -0.45764469  0.65533693 -1.19963244 -0.82863856 -0.45764469\n",
      " -1.19963244  1.39732467 -0.82863856  0.65533693  0.28434305 -0.45764469\n",
      " -0.45764469  1.76831854 -1.19963244  1.0263308  -0.82863856  0.28434305\n",
      " -0.08665082 -0.45764469 -1.19963244  1.76831854  2.13931242 -0.82863856\n",
      " -1.19963244 -0.45764469  1.0263308   1.39732467 -0.45764469 -1.19963244\n",
      " -1.19963244 -0.82863856 -0.08665082 -0.08665082 -1.19963244  2.13931242\n",
      "  0.65533693 -0.82863856 -0.45764469 -0.45764469 -1.19963244  1.0263308\n",
      " -1.19963244  0.28434305  0.28434305 -0.82863856  1.76831854 -0.82863856\n",
      "  1.39732467  1.39732467 -0.45764469 -0.45764469  1.0263308   0.28434305\n",
      "  0.28434305 -0.45764469 -0.45764469  2.13931242  1.39732467  1.39732467\n",
      " -0.82863856 -0.45764469  1.39732467 -0.82863856 -1.19963244  1.76831854\n",
      " -0.82863856 -0.82863856  2.13931242 -1.19963244 -0.45764469  0.65533693\n",
      "  0.28434305  0.28434305 -1.19963244  0.28434305  1.76831854 -0.82863856\n",
      " -0.08665082  0.28434305 -1.19963244  1.0263308  -0.82863856 -0.45764469\n",
      "  2.13931242 -1.19963244 -1.19963244 -0.45764469  1.0263308  -1.19963244\n",
      " -0.82863856 -0.08665082 -0.82863856 -0.45764469 -1.19963244  1.39732467\n",
      "  1.39732467 -0.45764469 -0.45764469 -0.08665082 -0.82863856  1.0263308\n",
      " -0.82863856 -0.82863856 -0.82863856  0.65533693  1.0263308   1.76831854\n",
      " -0.08665082 -0.45764469]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X.iloc[:, -4:] = scaler.fit_transform(X.iloc[:, -4:])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_32372\\3013115674.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.93905414 -0.93905414 -0.19143253 -0.93905414 -0.93905414 -0.93905414\n",
      " -0.19143253 -0.93905414  0.55618909 -0.19143253  2.05143233 -0.93905414\n",
      " -0.19143253 -0.93905414  1.30381071 -0.19143253  0.55618909  0.55618909\n",
      " -0.93905414 -0.19143253 -0.93905414 -0.93905414 -0.19143253  0.55618909\n",
      "  0.55618909 -0.19143253  0.55618909 -0.93905414  1.30381071  2.05143233\n",
      " -0.19143253 -0.93905414 -0.19143253  0.55618909 -0.93905414 -0.19143253\n",
      "  0.55618909 -0.19143253  1.30381071  2.05143233 -0.93905414  0.55618909\n",
      " -0.19143253 -0.93905414  0.55618909 -0.19143253  1.30381071 -0.19143253\n",
      " -0.93905414  0.55618909  1.30381071 -0.93905414 -0.19143253  0.55618909\n",
      "  1.30381071 -0.93905414  0.55618909 -0.19143253  0.55618909 -0.93905414\n",
      " -0.19143253 -0.93905414  1.30381071  0.55618909 -0.93905414 -0.93905414\n",
      " -0.19143253  0.55618909 -0.93905414 -0.19143253 -0.93905414  0.55618909\n",
      " -0.19143253 -0.93905414 -0.93905414 -0.19143253 -0.19143253 -0.93905414\n",
      "  2.05143233  0.55618909 -0.19143253  1.30381071 -0.93905414 -0.93905414\n",
      "  0.55618909 -0.93905414  1.30381071 -0.19143253 -0.93905414  0.55618909\n",
      " -0.19143253 -0.19143253 -0.93905414 -0.93905414 -0.93905414 -0.19143253\n",
      "  0.55618909 -0.93905414  1.30381071 -0.19143253 -0.93905414 -0.93905414\n",
      " -0.19143253  0.55618909 -0.93905414  1.30381071 -0.19143253 -0.93905414\n",
      "  0.55618909 -0.19143253 -0.93905414  0.55618909 -0.93905414 -0.19143253\n",
      "  1.30381071 -0.93905414 -0.19143253  0.55618909 -0.93905414 -0.93905414\n",
      " -0.93905414 -0.93905414  1.30381071 -0.19143253  0.55618909 -0.93905414\n",
      " -0.19143253 -0.93905414  1.30381071  0.55618909 -0.93905414 -0.19143253\n",
      " -0.93905414 -0.93905414  1.30381071 -0.93905414  0.55618909 -0.19143253\n",
      " -0.93905414 -0.93905414 -0.93905414 -0.19143253  0.55618909 -0.93905414\n",
      " -0.93905414 -0.19143253 -0.93905414  1.30381071 -0.93905414 -0.93905414\n",
      "  0.55618909 -0.19143253 -0.19143253 -0.93905414  1.30381071 -0.93905414\n",
      " -0.19143253  0.55618909 -0.93905414 -0.93905414 -0.19143253 -0.19143253\n",
      " -0.93905414 -0.93905414 -0.93905414 -0.93905414 -0.93905414 -0.19143253\n",
      " -0.19143253 -0.93905414 -0.93905414 -0.93905414  0.55618909  1.30381071\n",
      " -0.93905414 -0.93905414 -0.19143253 -0.19143253 -0.93905414 -0.19143253\n",
      " -0.93905414 -0.93905414 -0.93905414 -0.19143253 -0.19143253 -0.93905414\n",
      "  2.05143233 -0.19143253 -0.93905414  2.05143233 -0.19143253  1.30381071\n",
      " -0.93905414 -0.93905414  0.55618909 -0.19143253 -0.93905414 -0.93905414\n",
      " -0.93905414 -0.93905414 -0.93905414 -0.93905414 -0.19143253 -0.19143253\n",
      " -0.93905414  0.55618909 -0.93905414 -0.93905414 -0.93905414 -0.19143253\n",
      "  0.55618909 -0.19143253 -0.19143253 -0.19143253 -0.19143253  0.55618909\n",
      " -0.93905414  2.05143233  2.05143233  0.55618909  0.55618909 -0.93905414\n",
      "  2.05143233 -0.19143253 -0.93905414 -0.19143253  0.55618909 -0.93905414\n",
      " -0.19143253  2.05143233 -0.93905414 -0.93905414  2.05143233  1.30381071\n",
      " -0.93905414 -0.93905414 -0.93905414 -0.93905414 -0.93905414 -0.19143253\n",
      " -0.93905414  1.30381071 -0.19143253 -0.19143253 -0.19143253 -0.19143253\n",
      " -0.93905414 -0.19143253 -0.93905414  2.05143233 -0.93905414  1.30381071\n",
      "  2.05143233 -0.19143253 -0.93905414 -0.93905414  1.30381071 -0.19143253\n",
      " -0.93905414 -0.19143253  0.55618909 -0.93905414 -0.19143253 -0.93905414\n",
      " -0.93905414  2.05143233 -0.93905414 -0.19143253 -0.93905414 -0.93905414\n",
      " -0.19143253 -0.93905414  2.05143233 -0.93905414 -0.19143253 -0.19143253\n",
      "  1.30381071 -0.19143253 -0.93905414 -0.93905414  2.05143233 -0.19143253\n",
      "  2.05143233 -0.93905414 -0.93905414  2.05143233 -0.19143253 -0.93905414\n",
      "  0.55618909  1.30381071 -0.93905414 -0.19143253  0.55618909 -0.19143253\n",
      " -0.19143253 -0.93905414 -0.19143253 -0.19143253  2.05143233  2.05143233\n",
      "  1.30381071 -0.19143253 -0.19143253  1.30381071 -0.93905414  2.05143233\n",
      "  1.30381071 -0.93905414  2.05143233 -0.19143253  2.05143233 -0.93905414\n",
      "  1.30381071 -0.93905414 -0.93905414 -0.93905414  2.05143233 -0.93905414\n",
      "  0.55618909  2.05143233  2.05143233 -0.19143253 -0.19143253 -0.93905414\n",
      " -0.19143253 -0.93905414  0.55618909  0.55618909 -0.19143253 -0.93905414\n",
      " -0.93905414 -0.93905414 -0.93905414  2.05143233 -0.19143253 -0.93905414\n",
      "  0.55618909 -0.93905414 -0.19143253  2.05143233  0.55618909  0.55618909\n",
      " -0.19143253 -0.19143253  2.05143233  2.05143233  0.55618909 -0.19143253\n",
      "  2.05143233 -0.93905414 -0.19143253 -0.19143253 -0.19143253 -0.93905414\n",
      " -0.19143253 -0.19143253 -0.93905414 -0.93905414 -0.93905414 -0.93905414\n",
      " -0.19143253 -0.19143253 -0.93905414  0.55618909 -0.93905414  1.30381071\n",
      " -0.93905414 -0.19143253  1.30381071 -0.93905414  2.05143233  1.30381071\n",
      " -0.19143253  1.30381071 -0.93905414  0.55618909  1.30381071  0.55618909\n",
      "  2.05143233 -0.19143253 -0.93905414 -0.93905414 -0.93905414 -0.93905414\n",
      " -0.93905414 -0.93905414 -0.19143253 -0.93905414 -0.93905414 -0.93905414\n",
      " -0.93905414 -0.19143253  1.30381071 -0.19143253 -0.19143253 -0.93905414\n",
      "  2.05143233 -0.93905414  2.05143233 -0.19143253  0.55618909  2.05143233\n",
      " -0.19143253 -0.93905414 -0.93905414  0.55618909 -0.19143253 -0.93905414\n",
      " -0.93905414  2.05143233 -0.93905414 -0.19143253  0.55618909 -0.93905414\n",
      "  2.05143233 -0.19143253  2.05143233 -0.93905414 -0.19143253 -0.19143253\n",
      " -0.93905414 -0.93905414 -0.93905414 -0.19143253 -0.19143253 -0.93905414\n",
      " -0.19143253  1.30381071 -0.19143253 -0.19143253  0.55618909 -0.19143253\n",
      "  2.05143233 -0.19143253  1.30381071 -0.19143253  1.30381071 -0.19143253\n",
      " -0.19143253 -0.93905414  2.05143233  0.55618909  2.05143233 -0.19143253\n",
      "  1.30381071  0.55618909 -0.93905414 -0.19143253  1.30381071  2.05143233\n",
      " -0.93905414  0.55618909 -0.93905414 -0.93905414 -0.19143253 -0.93905414\n",
      " -0.93905414 -0.93905414 -0.19143253 -0.19143253 -0.93905414 -0.93905414\n",
      "  0.55618909  0.55618909 -0.93905414  2.05143233  2.05143233  1.30381071\n",
      " -0.93905414 -0.19143253  0.55618909 -0.93905414 -0.93905414 -0.19143253\n",
      " -0.93905414 -0.93905414 -0.19143253  0.55618909  2.05143233 -0.93905414\n",
      " -0.93905414  2.05143233 -0.19143253  0.55618909 -0.19143253 -0.93905414\n",
      " -0.93905414 -0.93905414 -0.19143253  2.05143233  0.55618909 -0.19143253\n",
      " -0.93905414 -0.19143253 -0.93905414 -0.19143253 -0.19143253 -0.19143253\n",
      " -0.19143253 -0.93905414  0.55618909  2.05143233 -0.93905414  1.30381071\n",
      "  0.55618909 -0.93905414 -0.19143253 -0.19143253 -0.19143253  0.55618909\n",
      " -0.93905414  2.05143233  0.55618909 -0.19143253  2.05143233 -0.19143253\n",
      "  0.55618909  1.30381071 -0.19143253 -0.19143253 -0.19143253 -0.19143253\n",
      "  2.05143233  0.55618909 -0.93905414 -0.93905414  2.05143233  2.05143233\n",
      " -0.19143253  2.05143233  1.30381071 -0.93905414 -0.19143253  0.55618909\n",
      " -0.19143253 -0.19143253  1.30381071 -0.19143253 -0.93905414  2.05143233\n",
      " -0.93905414 -0.19143253 -0.19143253  2.05143233  2.05143233 -0.19143253\n",
      "  1.30381071  2.05143233 -0.19143253  1.30381071 -0.19143253 -0.19143253\n",
      "  2.05143233 -0.19143253 -0.93905414 -0.93905414  1.30381071 -0.93905414\n",
      " -0.93905414  2.05143233 -0.93905414  0.55618909 -0.93905414  1.30381071\n",
      "  2.05143233 -0.19143253  2.05143233 -0.19143253 -0.19143253 -0.93905414\n",
      " -0.93905414 -0.19143253 -0.19143253 -0.93905414  2.05143233  2.05143233\n",
      " -0.93905414 -0.93905414]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X.iloc[:, -4:] = scaler.fit_transform(X.iloc[:, -4:])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_32372\\3013115674.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.99426374 -0.99426374 -0.80979409 -0.99426374 -0.93277385 -0.99426374\n",
      " -0.87128397 -0.74830421  2.01874049 -0.4408548   0.17404403 -0.87128397\n",
      " -0.4408548  -0.99426374  2.63363932 -1.05575362  0.48149344 -0.13340538\n",
      " -0.74830421 -0.56383456 -0.74830421 -0.93277385  0.17404403  0.05106426\n",
      "  0.48149344 -1.05575362  0.78894285 -0.80979409 -1.05575362  1.71129108\n",
      " -1.05575362 -0.87128397  0.17404403 -0.13340538 -0.99426374 -0.31787503\n",
      "  0.05106426 -1.05575362  0.78894285  2.3261899  -0.74830421  0.29702379\n",
      " -0.56383456 -0.74830421 -0.31787503 -1.05575362  1.09639226  0.05106426\n",
      " -0.56383456  0.17404403  0.78894285 -1.05575362 -0.74830421  0.48149344\n",
      "  0.29702379 -0.4408548   0.17404403 -0.56383456  0.48149344 -0.74830421\n",
      " -0.74830421 -1.05575362  1.40384167  0.05106426 -0.74830421 -0.93277385\n",
      " -0.4408548   0.48149344 -0.31787503 -0.56383456 -1.05575362  0.17404403\n",
      " -0.13340538 -0.4408548   0.48149344 -1.05575362 -0.31787503 -0.13340538\n",
      "  2.3261899   0.48149344  0.05106426  0.78894285 -1.05575362 -0.87128397\n",
      "  0.17404403 -0.87128397  0.78894285 -1.05575362 -0.4408548   1.09639226\n",
      "  0.48149344 -0.74830421 -0.13340538 -0.31787503 -0.56383456  0.17404403\n",
      "  0.78894285 -1.05575362  2.01874049  0.48149344 -1.05575362 -0.93277385\n",
      " -0.4408548   0.29702379 -0.56383456  2.63363932  0.17404403 -0.74830421\n",
      "  0.48149344 -0.13340538 -1.05575362  0.78894285 -0.68681432 -0.13340538\n",
      "  1.40384167 -1.05575362  0.48149344  0.05106426  0.17404403 -0.4408548\n",
      " -0.93277385 -1.05575362  1.09639226  0.17404403  1.40384167 -1.05575362\n",
      " -0.31787503 -0.56383456  2.01874049  0.78894285  0.05106426 -0.13340538\n",
      " -1.05575362 -0.4408548   0.48149344 -0.74830421  0.78894285  1.40384167\n",
      " -0.31787503 -1.05575362 -0.13340538  0.05106426  1.71129108  0.17404403\n",
      " -0.68681432  0.78894285 -0.56383456  0.48149344 -1.05575362 -0.31787503\n",
      "  0.17404403 -0.4408548   0.48149344 -1.05575362  1.40384167 -0.56383456\n",
      " -0.13340538  0.17404403 -0.4408548  -1.05575362  0.78894285  0.48149344\n",
      " -0.4408548  -0.31787503 -1.05575362 -0.56383456 -0.4408548  -0.13340538\n",
      "  0.17404403 -0.74830421  0.05106426 -1.05575362  0.78894285  1.71129108\n",
      " -0.13340538 -0.74830421  0.17404403 -0.31787503  1.34235179 -0.4408548\n",
      " -0.80979409 -0.80979409 -0.74830421 -0.62532444 -0.87128397 -0.50234468\n",
      "  0.78894285 -0.0719155  -1.05575362  1.95725061  2.38767979  1.28086191\n",
      "  0.05106426 -1.05575362  0.91192261 -0.74830421 -0.87128397 -0.74830421\n",
      "  1.58831132 -0.87128397  0.6044732   1.15788214 -0.99426374  2.26470002\n",
      " -0.4408548  -0.50234468 -0.80979409 -0.74830421  0.48149344  1.40384167\n",
      " -0.50234468 -0.74830421 -0.80979409 -0.87128397 -0.56383456 -0.13340538\n",
      " -0.37936491  1.28086191  0.29702379  0.6044732   2.38767979 -0.13340538\n",
      "  0.85043273 -0.50234468  1.6498012  -0.62532444  1.09639226 -0.74830421\n",
      " -1.05575362 -0.37936491 -0.99426374 -0.74830421  1.21937202  1.77278096\n",
      " -0.93277385  0.66596308 -0.31787503 -0.68681432 -0.4408548   1.21937202\n",
      " -0.01042562  1.09639226 -1.05575362  2.63363932 -1.05575362  1.71129108\n",
      " -0.93277385 -0.80979409 -1.05575362  0.23553391 -0.99426374  0.29702379\n",
      "  1.46533155 -0.87128397 -0.74830421 -0.56383456 -0.50234468 -0.99426374\n",
      " -0.80979409 -0.56383456  2.38767979 -0.62532444 -0.74830421 -0.93277385\n",
      " -0.99426374  1.77278096 -0.68681432 -0.68681432 -0.87128397 -0.99426374\n",
      " -1.05575362 -0.37936491  0.9734125   1.6498012   1.77278096 -0.62532444\n",
      " -0.0719155  -0.99426374  1.28086191 -0.56383456  2.38767979  0.6044732\n",
      "  1.46533155  1.71129108 -0.62532444  0.23553391 -0.99426374 -0.87128397\n",
      "  0.9734125   2.3261899  -0.99426374  0.78894285 -0.87128397 -0.87128397\n",
      " -0.74830421  0.11255414 -0.4408548  -0.80979409 -0.13340538  1.09639226\n",
      "  1.83427085 -0.62532444 -0.68681432  0.35851367  1.58831132  0.23553391\n",
      "  0.35851367 -0.99426374  2.44916967 -0.68681432  1.95725061 -0.80979409\n",
      " -0.37936491  1.03490238 -0.56383456 -0.4408548   2.63363932 -0.80979409\n",
      "  0.11255414  1.03490238  0.48149344 -0.62532444 -0.4408548   0.85043273\n",
      " -0.93277385 -0.50234468  0.78894285  0.11255414 -0.56383456 -0.99426374\n",
      " -0.80979409 -0.93277385 -1.05575362  0.72745297 -1.05575362 -0.74830421\n",
      "  2.51065955 -0.4408548   0.11255414  2.01874049  2.08023038  1.58831132\n",
      " -0.93277385 -0.56383456 -0.13340538  2.20321014 -0.25638515  1.09639226\n",
      "  2.63363932 -0.4408548  -0.99426374 -0.4408548  -0.50234468  1.77278096\n",
      " -0.99426374 -0.56383456 -0.56383456 -0.62532444 -0.68681432 -0.62532444\n",
      " -1.05575362 -0.87128397 -0.4408548  -0.56383456  0.23553391  1.6498012\n",
      "  2.08023038 -0.4408548   0.48149344 -0.93277385  1.09639226 -0.62532444\n",
      " -0.68681432  1.15788214 -0.87128397  1.95725061  1.15788214  0.66596308\n",
      "  0.35851367 -1.05575362 -0.68681432 -0.87128397 -0.99426374 -0.68681432\n",
      " -0.74830421 -0.56383456 -0.0719155  -0.74830421 -0.93277385 -0.62532444\n",
      " -0.56383456 -1.05575362 -0.31787503 -0.4408548  -0.19489527 -0.4408548\n",
      "  0.48149344 -0.99426374  0.78894285  0.05106426  1.83427085  1.21937202\n",
      "  0.91192261 -0.4408548   1.21937202 -0.01042562 -0.50234468 -0.74830421\n",
      " -0.74830421 -0.50234468 -0.74830421 -0.50234468  0.9734125  -0.56383456\n",
      " -0.62532444 -0.93277385 -0.37936491 -0.68681432 -0.80979409 -0.50234468\n",
      " -0.99426374 -0.74830421 -1.05575362 -0.4408548  -1.05575362 -0.74830421\n",
      "  0.29702379  1.15788214 -0.56383456 -0.4408548  -0.50234468  1.40384167\n",
      "  1.21937202 -0.50234468  1.58831132 -0.80979409  1.21937202  0.35851367\n",
      " -0.50234468  1.77278096  1.40384167  1.58831132  0.6044732  -0.87128397\n",
      "  0.23553391  1.89576073 -1.05575362  1.28086191 -0.50234468  2.38767979\n",
      " -0.93277385 -0.31787503  0.66596308 -0.56383456 -0.50234468  0.85043273\n",
      " -0.93277385 -0.4408548  -1.05575362  2.01874049  2.26470002 -0.93277385\n",
      "  1.95725061 -0.50234468  1.15788214  1.95725061  0.72745297 -0.74830421\n",
      " -1.05575362 -0.62532444  1.34235179 -0.93277385 -0.99426374 -0.74830421\n",
      " -1.05575362  0.11255414 -0.4408548   1.34235179  0.05106426 -0.4408548\n",
      " -0.62532444  1.95725061 -0.74830421 -0.31787503 -0.62532444  2.44916967\n",
      " -0.80979409 -0.74830421 -1.05575362  0.23553391  2.20321014 -0.74830421\n",
      " -0.4408548  -0.62532444  0.72745297 -1.05575362 -0.74830421 -0.50234468\n",
      " -0.93277385 -0.68681432  1.52682144  1.77278096  1.77278096  2.3261899\n",
      " -0.68681432 -0.62532444 -0.87128397 -0.4408548  -0.99426374  0.54298332\n",
      " -1.05575362 -0.4408548   1.34235179 -1.05575362  1.95725061 -0.68681432\n",
      "  0.11255414  0.17404403  1.21937202  2.3261899   1.21937202  0.6044732\n",
      "  0.91192261 -0.99426374 -0.74830421  1.83427085  1.28086191  0.29702379\n",
      " -0.99426374  2.63363932  0.42000356 -0.50234468 -0.56383456  0.6044732\n",
      " -0.87128397 -0.80979409  0.11255414 -0.50234468 -0.62532444  0.66596308\n",
      " -0.56383456 -0.62532444 -0.80979409  0.85043273  0.66596308 -0.74830421\n",
      " -0.31787503 -0.37936491 -1.05575362  1.83427085 -0.0719155  -0.68681432\n",
      "  0.11255414 -0.80979409 -0.4408548  -0.80979409  0.54298332 -0.87128397\n",
      " -0.4408548   1.03490238 -0.56383456 -0.4408548  -0.80979409 -0.37936491\n",
      " -0.13340538 -0.74830421  2.57214943  0.35851367 -0.56383456 -0.93277385\n",
      " -1.05575362 -1.05575362 -1.05575362  2.63363932  2.26470002  0.17404403\n",
      "  0.66596308 -0.62532444]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X.iloc[:, -4:] = scaler.fit_transform(X.iloc[:, -4:])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_32372\\3013115674.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.10889348 -0.93261723 -1.10889348 -0.93261723 -1.10889348 -1.10889348\n",
      " -0.58006474 -0.75634099 -0.22751225 -1.10889348  1.53525021 -1.10889348\n",
      " -0.93261723 -0.93261723 -0.22751225  1.53525021  0.65386898 -0.22751225\n",
      " -0.75634099 -1.10889348 -1.10889348 -0.93261723 -0.58006474  0.65386898\n",
      " -0.22751225  2.41663144  0.65386898 -1.10889348 -1.10889348  3.29801267\n",
      " -0.22751225 -0.93261723 -0.22751225 -0.75634099 -1.10889348 -0.58006474\n",
      " -0.22751225  0.65386898 -0.22751225  0.65386898 -1.10889348  0.30131649\n",
      " -1.10889348 -0.75634099 -0.40378849 -0.58006474 -0.75634099 -0.22751225\n",
      " -0.75634099 -0.93261723  1.53525021  0.30131649 -1.10889348  0.65386898\n",
      " -0.051236   -0.93261723  0.65386898 -0.58006474 -0.22751225 -0.75634099\n",
      " -1.10889348  1.00642147  0.65386898 -0.22751225 -1.10889348 -0.93261723\n",
      " -0.22751225  0.65386898 -0.93261723 -0.58006474 -0.40378849 -0.75634099\n",
      " -0.58006474 -0.93261723 -1.10889348  0.65386898 -0.051236   -0.75634099\n",
      "  2.41663144  0.30131649 -0.22751225  0.65386898  1.53525021 -0.93261723\n",
      " -0.22751225 -0.93261723  1.00642147  2.41663144 -0.75634099 -0.22751225\n",
      "  0.30131649 -0.93261723 -0.75634099 -0.93261723 -0.58006474  0.65386898\n",
      " -0.40378849  1.00642147  1.53525021 -0.051236   -0.22751225 -1.10889348\n",
      " -0.58006474  0.12504024 -0.93261723  2.41663144  0.30131649 -0.93261723\n",
      "  0.65386898 -0.22751225  0.30131649 -0.58006474 -0.93261723 -0.40378849\n",
      "  1.00642147  0.65386898 -0.051236    0.12504024 -0.93261723 -0.93261723\n",
      " -1.10889348  0.30131649  1.53525021 -0.22751225  1.00642147  3.29801267\n",
      " -0.58006474 -0.93261723  0.65386898  1.00642147 -0.93261723 -0.40378849\n",
      " -0.051236   -0.93261723  0.30131649 -0.75634099 -0.051236    0.65386898\n",
      " -0.58006474  0.30131649 -0.75634099 -0.22751225 -0.22751225 -0.93261723\n",
      " -0.75634099  0.65386898 -1.10889348  0.30131649 -0.051236   -0.75634099\n",
      "  0.12504024 -0.58006474 -0.40378849  1.00642147  1.53525021 -0.93261723\n",
      " -0.051236    0.12504024 -0.75634099  0.30131649 -0.051236   -0.22751225\n",
      " -0.58006474 -0.75634099  0.65386898 -0.75634099 -0.93261723 -0.22751225\n",
      "  0.12504024 -0.58006474 -0.93261723 -0.22751225  0.65386898  1.00642147\n",
      " -0.75634099 -0.75634099 -0.22751225 -0.58006474  1.00642147 -0.75634099\n",
      " -0.22751225 -0.40378849 -1.10889348 -0.22751225 -0.58006474 -0.75634099\n",
      "  0.47759274 -0.75634099 -0.40378849  2.2403552   0.65386898 -0.75634099\n",
      " -0.22751225 -1.10889348  1.53525021 -1.10889348 -1.10889348 -0.40378849\n",
      "  1.53525021 -1.10889348 -0.22751225  2.41663144 -0.93261723  0.12504024\n",
      "  2.06407895  1.35897397 -0.93261723 -1.10889348 -0.22751225  2.06407895\n",
      " -0.40378849 -1.10889348 -0.58006474 -0.40378849 -0.58006474  1.88780271\n",
      "  1.18269772 -0.58006474  1.00642147  0.30131649  1.71152646  2.2403552\n",
      "  1.18269772 -0.93261723 -0.22751225 -0.93261723  2.06407895 -0.93261723\n",
      " -0.93261723 -0.051236   -0.22751225 -0.75634099  0.65386898  0.12504024\n",
      " -0.58006474  1.35897397 -0.051236   -0.40378849  2.06407895  0.47759274\n",
      "  3.12173643  0.30131649 -0.22751225  1.35897397 -0.93261723  0.47759274\n",
      " -0.75634099 -0.93261723 -0.40378849  1.35897397 -0.58006474  1.00642147\n",
      "  1.88780271 -0.22751225 -0.40378849 -0.22751225 -0.75634099 -0.58006474\n",
      " -1.10889348 -0.58006474 -0.75634099 -0.58006474 -0.40378849 -0.22751225\n",
      " -0.40378849  0.47759274 -1.10889348 -0.40378849 -0.75634099 -0.40378849\n",
      " -0.40378849  0.65386898 -0.40378849 -0.22751225  0.12504024 -0.58006474\n",
      "  0.30131649 -0.22751225  2.2403552  -0.58006474  0.65386898  0.47759274\n",
      "  1.88780271  1.53525021 -0.40378849 -0.40378849 -0.93261723 -0.58006474\n",
      "  2.06407895  0.83014523 -0.75634099  1.88780271 -0.93261723 -0.93261723\n",
      "  2.06407895  0.83014523 -0.75634099 -1.10889348 -0.22751225  0.65386898\n",
      "  1.35897397 -0.40378849 -0.58006474  2.41663144  2.06407895  2.2403552\n",
      " -0.58006474 -0.40378849  2.06407895 -0.40378849  1.53525021 -0.75634099\n",
      "  1.71152646  0.65386898 -0.58006474 -0.58006474 -0.22751225 -0.40378849\n",
      "  0.65386898  0.30131649  1.71152646 -0.22751225 -0.93261723  1.35897397\n",
      " -1.10889348 -1.10889348  1.18269772 -0.22751225 -0.58006474 -0.75634099\n",
      " -0.22751225 -0.22751225 -0.75634099  1.71152646 -0.58006474 -0.40378849\n",
      "  1.18269772 -0.75634099  0.47759274  0.30131649  1.53525021  0.47759274\n",
      " -0.93261723 -0.58006474 -0.75634099  1.88780271  1.53525021 -0.58006474\n",
      " -0.75634099 -0.40378849 -0.58006474 -1.10889348 -0.75634099  1.00642147\n",
      " -0.22751225  2.2403552  -0.75634099 -0.58006474 -0.40378849 -0.58006474\n",
      " -0.93261723 -0.93261723  4.17939391 -0.40378849 -0.40378849  1.35897397\n",
      "  1.53525021 -0.58006474  1.88780271 -1.10889348  1.00642147 -0.40378849\n",
      " -0.40378849  2.41663144 -0.75634099 -0.58006474  1.53525021 -0.75634099\n",
      "  1.18269772 -0.40378849 -0.93261723 -0.75634099 -0.40378849 -0.22751225\n",
      " -0.58006474 -0.93261723 -0.40378849 -0.58006474 -0.22751225 -0.22751225\n",
      "  1.88780271 -1.10889348  1.53525021 -0.93261723  1.88780271 -0.40378849\n",
      " -0.40378849 -0.93261723 -0.75634099  1.71152646  1.18269772 -0.051236\n",
      "  2.06407895 -0.40378849 -0.75634099 -0.051236    1.88780271 -1.10889348\n",
      " -0.75634099  0.12504024 -0.75634099 -0.75634099  1.18269772 -0.40378849\n",
      "  1.18269772 -0.93261723  1.35897397 -0.75634099 -0.93261723 -0.75634099\n",
      " -0.22751225 -0.93261723 -0.58006474 -0.22751225 -0.58006474 -0.40378849\n",
      " -0.22751225  2.2403552  -0.58006474 -0.58006474 -0.75634099  0.47759274\n",
      "  0.47759274 -1.10889348  0.12504024 -1.10889348  1.71152646  1.88780271\n",
      " -1.10889348  0.65386898 -0.22751225  0.30131649  0.83014523 -0.22751225\n",
      "  0.47759274  0.30131649 -0.40378849  2.2403552   0.30131649  2.2403552\n",
      " -0.22751225  1.88780271  1.00642147 -0.22751225 -0.22751225  0.12504024\n",
      " -0.58006474 -1.10889348 -0.58006474 -0.22751225 -0.58006474 -1.10889348\n",
      "  0.30131649  1.88780271 -0.22751225  2.2403552   1.71152646  2.41663144\n",
      " -0.40378849 -0.22751225 -0.051236   -0.40378849 -0.58006474 -0.75634099\n",
      " -0.93261723 -0.051236   -0.75634099  1.18269772  1.88780271 -0.93261723\n",
      " -0.58006474  1.00642147 -0.22751225  0.30131649 -0.58006474  0.83014523\n",
      " -0.22751225 -0.58006474 -0.22751225  0.12504024  0.12504024 -0.22751225\n",
      " -0.58006474 -0.75634099  0.12504024 -1.10889348 -1.10889348 -1.10889348\n",
      " -1.10889348 -0.22751225 -0.40378849  0.30131649  3.65056517 -0.40378849\n",
      "  0.12504024 -0.58006474 -0.75634099 -0.93261723 -0.22751225 -0.58006474\n",
      " -0.75634099  1.71152646  0.47759274 -0.58006474  1.53525021 -0.22751225\n",
      "  0.12504024  0.47759274  0.65386898 -0.75634099  2.2403552  -0.40378849\n",
      "  1.71152646 -0.58006474 -0.40378849  1.53525021  0.47759274  2.41663144\n",
      " -0.93261723 -0.22751225 -0.40378849 -0.40378849 -0.58006474  1.35897397\n",
      " -0.93261723 -0.75634099  0.12504024 -0.40378849 -0.22751225 -0.40378849\n",
      "  0.47759274  0.30131649 -0.40378849  1.88780271  1.18269772 -0.75634099\n",
      " -0.40378849 -0.051236   -1.10889348 -0.40378849  0.83014523 -0.22751225\n",
      " -0.051236   -0.75634099 -0.40378849 -0.22751225 -0.75634099 -1.10889348\n",
      " -0.93261723 -0.22751225 -1.10889348  0.47759274 -0.93261723  1.00642147\n",
      " -0.58006474 -1.10889348 -0.40378849  1.00642147 -0.93261723 -0.75634099\n",
      " -0.93261723 -0.93261723 -0.75634099  2.06407895  0.47759274 -0.58006474\n",
      "  0.83014523 -0.93261723]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X.iloc[:, -4:] = scaler.fit_transform(X.iloc[:, -4:])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, recall_score\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"data_csv.csv\")\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "\n",
    "# Convert the label to binary values (spam=1, not spam=0)\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Extract features and label\n",
    "X_text = data['title']\n",
    "X_numeric = data[['comments', 'files_changed', 'lines_added', 'lines_removed']]\n",
    "y = data['label']\n",
    "\n",
    "# Apply TF-IDF to the text feature\n",
    "tfidf = TfidfVectorizer(max_features=100)  # Limit features to 100 for simplicity\n",
    "X_text_tfidf = tfidf.fit_transform(X_text).toarray()\n",
    "\n",
    "# Concatenate text and numeric features\n",
    "X = pd.concat([pd.DataFrame(X_text_tfidf), X_numeric.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Normalize the numeric features\n",
    "scaler = StandardScaler()\n",
    "X.iloc[:, -4:] = scaler.fit_transform(X.iloc[:, -4:])\n",
    "\n",
    "# Step 2: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: KNN Classifier Training\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust 'n_neighbors' as needed\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_precision = precision_score(y_test, y_pred)\n",
    "knn_f1 = f1_score(y_test, y_pred)\n",
    "knn_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "knn_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {knn_accuracy:.2f}\")\n",
    "print(f\"Precision: {knn_precision:.2f}\")\n",
    "print(f\"F1 Score: {knn_f1:.2f}\")\n",
    "print(f\"Recall: {knn_recall:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", knn_conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "F1 Score: 0.92\n",
      "Recall: 0.95\n",
      "Confusion Matrix:\n",
      " [[87  9]\n",
      " [ 4 74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, recall_score\n",
    "\n",
    "# Assume the preprocessing steps (TF-IDF, label encoding, normalization) are done\n",
    "# and we have X_train, X_test, y_train, y_test as before\n",
    "\n",
    "# Step 1: Initialize and train the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)  # You can also adjust hyperparameters like max_depth\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Prediction and Evaluation\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "decision_tree_accuracy = accuracy_score(y_test, y_pred)\n",
    "decision_tree_precision = precision_score(y_test, y_pred)\n",
    "decision_tree_f1 = f1_score(y_test, y_pred)\n",
    "decision_tree_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "decision_tree_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {decision_tree_accuracy:.2f}\")\n",
    "print(f\"Precision: {decision_tree_precision:.2f}\")\n",
    "print(f\"F1 Score: {decision_tree_f1:.2f}\")\n",
    "print(f\"Recall: {decision_tree_recall:.2f}\")\n",
    "print(f\"Confusion Matrix:\\n\", decision_tree_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results without 'title' feature:\n",
      "Accuracy: 0.8879310344827587\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.8653846153846154\n",
      "F1 Score: 0.8737864077669902\n",
      "Confusion Matrix:\n",
      " [[58  6]\n",
      " [ 7 45]]\n",
      "\n",
      "Random Forest Results with 'title' feature:\n",
      "Accuracy: 0.9655172413793104\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9629629629629629\n",
      "Confusion Matrix:\n",
      " [[60  4]\n",
      " [ 0 52]]\n",
      "\n",
      "Logistic Regression Results without 'title' feature:\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.896551724137931\n",
      "Precision: 0.8703703703703703\n",
      "Recall: 0.9038461538461539\n",
      "F1 Score: 0.8867924528301887\n",
      "Confusion Matrix:\n",
      " [[57  7]\n",
      " [ 5 47]]\n",
      "\n",
      "Logistic Regression Results with 'title' feature:\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.9482758620689655\n",
      "Precision: 0.9423076923076923\n",
      "Recall: 0.9423076923076923\n",
      "F1 Score: 0.9423076923076923\n",
      "Confusion Matrix:\n",
      " [[61  3]\n",
      " [ 3 49]]\n",
      "\n",
      "KNN Results:\n",
      "Accuracy: 0.9655172413793104\n",
      "Precision: 0.9285714285714286\n",
      "F1 Score: 0.9629629629629629\n",
      "Recall: 1.0\n",
      "Confusion Matrix:\n",
      " [[90  6]\n",
      " [ 0 78]]\n",
      "\n",
      "Decision Tree Results:\n",
      "Accuracy: 0.9252873563218391\n",
      "Precision: 0.891566265060241\n",
      "F1 Score: 0.9192546583850931\n",
      "Recall: 0.9487179487179487\n",
      "Confusion Matrix:\n",
      " [[87  9]\n",
      " [ 4 74]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Results without 'title' feature:\")\n",
    "print(\"Accuracy:\", random_forest_accuracy)\n",
    "print(\"Precision:\", random_forest_precision)\n",
    "print(\"Recall:\", random_forest_recall)\n",
    "print(\"F1 Score:\", random_forest_f1)\n",
    "print(\"Confusion Matrix:\\n\", random_forest_conf_matrix)\n",
    "\n",
    "print(\"\\nRandom Forest Results with 'title' feature:\")\n",
    "print(\"Accuracy:\", random_forest_with_TITLE_accuracy)\n",
    "print(\"Precision:\", random_forest_with_TITLE_precision)\n",
    "print(\"Recall:\", random_forest_with_TITLE_recall)\n",
    "print(\"F1 Score:\", random_forest_with_TITLE_f1)\n",
    "print(\"Confusion Matrix:\\n\", random_forest_with_TITLE_conf_matrix)\n",
    "\n",
    "print(\"\\nLogistic Regression Results without 'title' feature:\")\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", logistice_regression_accuracy)\n",
    "print(\"Precision:\", logistice_regression_precision)\n",
    "print(\"Recall:\", logistice_regression_recall)\n",
    "print(\"F1 Score:\", logistice_regression_f1)\n",
    "print(\"Confusion Matrix:\\n\", logistice_regression_conf_matrix)\n",
    "\n",
    "print(\"\\nLogistic Regression Results with 'title' feature:\")\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", logistice_regression_with_TITLE_accuracy)\n",
    "print(\"Precision:\", logistice_regression_with_TITLE_precision)\n",
    "print(\"Recall:\", logistice_regression_with_TITLE_recall)\n",
    "print(\"F1 Score:\", logistice_regression_with_TITLE_f1)\n",
    "print(\"Confusion Matrix:\\n\", logistice_regression_with_TITLE_conf_matrix)\n",
    "\n",
    "print(\"\\nKNN Results:\")\n",
    "print(f\"Accuracy: {knn_accuracy}\")\n",
    "print(f\"Precision: {knn_precision}\")\n",
    "print(f\"F1 Score: {knn_f1}\")\n",
    "print(f\"Recall: {knn_recall}\")\n",
    "print(\"Confusion Matrix:\\n\", knn_conf_matrix)\n",
    "\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(f\"Accuracy: {decision_tree_accuracy}\")\n",
    "print(f\"Precision: {decision_tree_precision}\")\n",
    "print(f\"F1 Score: {decision_tree_f1}\")\n",
    "print(f\"Recall: {decision_tree_recall}\")\n",
    "print(f\"Confusion Matrix:\\n\", decision_tree_conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
